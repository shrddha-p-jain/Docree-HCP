# -*- coding: utf-8 -*-
"""3. Modelling Final Taxonomy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CgaEe6lMbJeGgqp2aHlOF2qy4ljLKxDY
"""

# use data to train the final model. before that all training is done on train and test set is used just for purpose of comparing.
# comment out test codes for final training.
#

import pandas as pd
import scipy.stats as stats
import numpy as np
from category_encoders import MEstimateEncoder
from category_encoders.count import CountEncoder
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
import pycaret
from pycaret.classification import *

train = pd.read_parquet(r'train_mee_tf.parquet')
test= pd.read_parquet(r'test_mee_tf.parquet')
data_test_final = pd.read_parquet(r'data_test_final_me_tf.parquet')

train = train[~(train.TAXONOMY_Pred.isin(['Not Doctor','Unknown']))]

test = test[~(test.TAXONOMY_Pred.isin(['Not Doctor','Unknown']))]

train = train.drop(['DEVICETYPE', 'PLATFORM_ID', 'BIDREQUESTIP', 'USERPLATFORMUID', 'USERCITY', 'USERZIPCODE', 'USERAGENT', 'PLATFORMTYPE', 'CHANNELTYPE',
       'URL', 'KEYWORDS', 'TAXONOMY', 'IS_HCP','Code',
       'Classification', 'TAX1', 'is_h', 'IP1', 'IP2', 'IP3', 'IP4', 'device_brand', 'device_family', 'device_model', 'os', 'ua'],axis=1,inplace = True)

test = test.drop(['DEVICETYPE', 'PLATFORM_ID', 'BIDREQUESTIP', 'USERPLATFORMUID', 'USERCITY', 'USERZIPCODE', 'USERAGENT', 'PLATFORMTYPE', 'CHANNELTYPE',
       'URL', 'KEYWORDS', 'TAXONOMY', 'IS_HCP','Code',
       'Classification', 'TAX1', 'is_h', 'IP1', 'IP2', 'IP3', 'IP4', 'device_brand', 'device_family', 'device_model', 'os', 'ua'],axis=1,inplace = True)

data_test_final = data_test_final.drop(['DEVICETYPE', 'PLATFORM_ID', 'BIDREQUESTIP', 'USERPLATFORMUID', 'USERCITY', 'USERZIPCODE', 'USERAGENT', 'PLATFORMTYPE', 'CHANNELTYPE',
       'URL', 'KEYWORDS', 'TAXONOMY', 'IS_HCP','Code',
       'Classification', 'TAX1', 'is_h', 'IP1', 'IP2', 'IP3', 'IP4', 'device_brand', 'device_family', 'device_model', 'os', 'ua'],axis=1,inplace = True)

# use data to train the final model. before that all training is done on train and test set is used just for purpose of comparing.
# data = pd.concat([train,test])
# data.reset_index(drop=True,inplace = True)



# import pycaret classification and init setup

s = setup(train, target = 'TAXONOMY_Pred', session_id = 101,train_size=0.80,imputation_type = 'iterative', fold_shuffle=True,

                  experiment_name = 'train_me_tf',ignore_features=["ID"],max_encoding_ohe=100)

best_N = compare_models(n_select=5,fold = 5)

pred0 = predict_model(best_N[0],test)
pred1 = predict_model(best_N[1],test)
pred2 = predict_model(best_N[2],test)
pred3 = predict_model(best_N[3],test)
pred4 = predict_model(best_N[4],test)

save_model(best_N[0],'is_h_1')
save_model(best_N[1],'is_h_2')
save_model(best_N[2],'is_h_3')
save_model(best_N[3],'is_h_4')
save_model(best_N[4],'is_h_5')

tuned_models = [tune_model(model,fold=5) for model in best_N]

save_model(tuned_models[0],'tuned_is_h_1')
save_model(tuned_models[1],'tuned_is_h_2')
save_model(tuned_models[2],'tuned_is_h_3')
save_model(tuned_models[3],'tuned_is_h_4')
save_model(tuned_models[4],'tuned_is_h_5')

predt0 = predict_model(tuned_models[0],test)
predt1 = predict_model(tuned_models[1],test)
predt2 = predict_model(tuned_models[2],test)
predt3 = predict_model(tuned_models[3],test)
predt4 = predict_model(tuned_models[4],test)

blend1 = blend_models(estimator_list=tuned_models,fold = 5)
save_model(blend1,'blend5_is_h')

stack1 = stack_models(estimator_list=tuned_models,fold = 5)
save_model(stack1,'stack5_is_h')

blend2 = blend_models(estimator_list=tuned_models[:2],fold = 5)
save_model(blend2,'blend2_is_h')
stack2 = stack_models(estimator_list=tuned_models[:2],fold = 5)
save_model(stack2,'stack2_is_h')

preds1 = predict_model(stack1,test)
preds2 = predict_model(stack2,test)
predb1 = predict_model(blend1,test)
predb2 = predict_model(blend2,test)



#save_model(stack1,'stack1_notune_me_tf_h')

is_h = pd.read_csv(r'submission_final.csv')
data_test_final_me_tf1 = data_test_final_me_tf[~data_test_final_me_tf.ID.isin(is_h.ID)]

pred0 = predict_model(stack5,data_test_final_me_tf1)
pred0.to_parquet(r'best0.parquet')
pred0 = pd.merge(pred0,data_test_final[['ID','USERPLATFORMUID']],on = 'ID',how = 'left')
pred0.rename({'predicted_label':'TAXONOMY'},axis=1,inplace = True)
pred0[['ID','IS_HCP','TAXONOMY']].to_csv(r'submission_final_taxonomy',index = False)

best = stack5

# plot confusion matrix
plot_model(best, plot = 'confusion_matrix')

# plot AUC
plot_model(best, plot = 'auc')

plot_model(best, plot = 'feature')